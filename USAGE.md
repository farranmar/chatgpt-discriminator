# ChatGPT Discriminator

## Available models
There are two trained models available: `rephrased` and `from-titles`. The `rephrased` model was trained for 10 epochs as outlined in the Methods section of the [README](README.md) on human-written abstracts and abstracts rephrased by ChatGPT. The `from-titles` model was similarly trained for 10 epochs on human written abstracts and abstracts generated by ChatGPT from the title of the associated paper. Unfortunately, due to GitHub file size limits and a lack of free options for hosting these saved models, they are not avilable on this repository. However, if you wish to access the models, please email the author at farran_regan@brown.edu, and we can arrange access to the trained models.

## Running the model
To run the model, install the required dependencies fonud in `dependencies.yml`, then run `python model.py`  
<br>
With no arguments set, the default behavior when running `model.py` is to start training the model for 10 epochs on human written absrtacts and those rephrased by ChatGPT. To train with different options or to test the model instead, see the following optional arguments:  

`--save_weights`: takes a string representing the name you want to give the model you train, which will be the name of the folder it is saved in in the `model_checkpts` folder  
`--load_weights`: takes a string representing the name of the model (in `model_checkpts`) that you want to load and use for training/testing  
`--test`: will test the model instead of training; takes a string representing the name of the model (in `model_checkpts`) that you want to test (this uses our testing data)  
`--predict_gui`: will allow the user to provide an input, runs the model on that input and prints the outputted prediction  
`--bert`: indicates the model should use BERT instead of distilBERT (note this will use a significant amount of time and memory)  
`--from_titles`: indicates you want to use the data generated from paper titles rather than rephrased from human-written abstracts  
`--batch_size`: takes an int of the batch size you wish to use; defaults to 256  
`--num_epochs`: takes an int of the number of epochs you want to train the model for; defaults to 10  
`--percent_data`: takes a float of the proportion of data you wish to use for training and testing; defaults to 1  
`--max_num_tokens`: takes an int of the max number of tokens to use when tokenizing inputs; defaults to 512  




